# GeM2-14B-Korean-RAG-QLoRA


---
- **ê¸°ê°„** : 2024.05 â€“ 2025.06
---

## ğŸ“Œ ëŒ€íšŒ ì†Œê°œ

- **ê¸°ê´€ëª…:** í•œêµ­ì •ë³´ê³¼í•™íšŒ X VAIV Company  
- **ëŒ€íšŒëª…:** í•œêµ­ì–´ ê²€ìƒ‰ ìš”ì•½(Open-Book QA) ëª¨ë¸ ê°œë°œ ëŒ€íšŒ  
- **ì£¼ì œ:** ì°¸ì¡° ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª… ìš”ì•½ + ì •ë‹µì„ ìƒì„±í•˜ëŠ” í•œêµ­ì–´ LLM ê°œë°œ  

![VAIV_llm_contest](https://github.com/user-attachments/assets/6708eedc-0260-4a0f-b139-73992d20b4cb)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ

- ë‹¨ìˆœ ìœ ì‚¬ë„ ê¸°ë°˜ RAGì˜ í•œê³„ ê°œì„   
- ë¬¸ì„œ ìœ ìš©ì„± í‰ê°€ë¥¼ í†µí•œ ì‹ ë¢°ë„ í–¥ìƒ  
- ê·¼ê±° ê¸°ë°˜ ì„¤ëª… ìš”ì•½ + ì •ë‹µ ìƒì„±  
- QLoRA ê¸°ë°˜ 14B ëª¨ë¸ íš¨ìœ¨ì  íŒŒì¸íŠœë‹  

---

## ğŸ§  LLM ì•„í‚¤í…ì²˜

![LLM_Architecture](https://github.com/user-attachments/assets/724d59da-96ec-4908-b3fb-9b95967fea22)

---

## ğŸ”§ ì‚¬ìš©í•œ ì£¼ìš” ê¸°ìˆ 

### 1ï¸âƒ£ RAG (Retrieval-Augmented Generation)

#### ğŸ“Œ Indexing
- ë¬¸ì„œë¥¼ chunk ë‹¨ìœ„ë¡œ ë¶„í•   
- ì„ë² ë”© ìƒì„±  
- ë²¡í„° DB ì €ì¥  

#### ğŸ“Œ Retrieval
- ì§ˆë¬¸ê³¼ ë²¡í„° ìœ ì‚¬ë„ ë¹„êµ  
- Top-k ë¬¸ì„œ ì¶”ì¶œ  
- LLM ê¸°ë°˜ 1ì°¨ í•„í„° ì ìš©

![RAG_Architecture](https://github.com/user-attachments/assets/d2e10a65-ac86-4289-ae67-6b324f42fdee)

---

### 2ï¸âƒ£ DocQuest Evaluation

**ì…ë ¥:** (ì§ˆë¬¸, ê²€ìƒ‰ ë¬¸ì„œ)  
**ì¶œë ¥:** 0~1 ìœ ìš©ì„± ì ìˆ˜  

- threshold ì´ìƒ ë¬¸ì„œë§Œ ìµœì¢… ì…ë ¥ ì‚¬ìš©  

#### ğŸ¯ íš¨ê³¼
- ë¬´ê´€ ë¬¸ì„œ ì œê±°  
- í™˜ê° ê°ì†Œ  
- ì‹ ë¢°ë„ í–¥ìƒ  

---

### 3ï¸âƒ£ Ko-QAS Model

- í•µì‹¬ ë‚´ìš© ìš”ì•½  
- ìš”ì•½ ê¸°ë°˜ ì •ë‹µ ìƒì„±  
- ê·¼ê±° ê¸°ë°˜ Long Answer ìƒì„±  

---

# ğŸ“š ë°ì´í„°ì…‹ ìƒì„± ì „ëµ

ì´ **3ë‹¨ê³„ ë°ì´í„° ìƒì„± ì „ëµ** ì‚¬ìš©

---

## 1ï¸âƒ£ ê¸°ì¡´ QA ë°ì´í„° í™•ì¥ (ë¬¸ì„œ-ì§ˆì˜-ë‹µë³€ â†’ ìš”ì•½ ì¶”ê°€)

### ğŸ“Œ ì‚¬ìš© ë°ì´í„°
- AIHub í‘œ ì •ë³´ ì§ˆì˜ì‘ë‹µ  
- KorQuAD 2.0  
- ì—‘ì†Œë¸Œë ˆì¸ MRC ë“±  

### ğŸ”§ ì²˜ë¦¬ ë°©ì‹
- OpenAI API í™œìš©  
- ë‹µë³€ì„ ì„¤ëª…í•˜ëŠ” ìš”ì•½(summary) ìƒì„±  

### ğŸ“‚ ìµœì¢… êµ¬ì¡°
```
ë¬¸ì„œ â†’ ì§ˆì˜ â†’ ìš”ì•½ â†’ ë‹µë³€
```

---

## 2ï¸âƒ£ ë¬¸ì„œ-ìš”ì•½ ë°ì´í„° â†’ QA êµ¬ì¡° ë³€í™˜

### ğŸ“Œ ì‚¬ìš© ë°ì´í„°
- AIHub ë¬¸ì„œìš”ì•½ í…ìŠ¤íŠ¸  

### ğŸ”§ ì²˜ë¦¬ ë°©ì‹
- ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ ìƒì„±  
- ìš”ì•½ ê¸°ë°˜ ë‹µë³€ ìƒì„±  
- QA í•™ìŠµ í˜•íƒœë¡œ ì¬êµ¬ì„±  

---

## 3ï¸âƒ£ ìµœì‹  ë°ì´í„° ë° ë…¼ë¬¸ ë°ì´í„° ì¶”ê°€

### ğŸ“Œ ì‚¬ìš© ë°ì´í„°
- MarkAI Ko-commercial dataset  
- êµ­ë‚´ ë…¼ë¬¸ QA 2.0  
- KorSciQA 1.0 / 2.0  
- 2024ë…„ ì´í›„ ê¸°ì‚¬ í¬ë¡¤ë§  

### ğŸ”§ ì²˜ë¦¬ ë°©ì‹
- ì§ˆë¬¸ ìƒì„±  
- ë‹µë³€ ìƒì„±  
- ê±°ì§“ ì •ë³´ ì œê±°  
- ì‹ ë¢°ì„± ê²€ì¦  

---

# ğŸŒ ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸

| ë„ë©”ì¸ | ë°ì´í„°ì…‹ ì´ë¦„ |
|--------|----------------|
| ë‹¤ì–‘í•¨ | KorQuAD 2.0 |
| ë‹¤ì–‘í•¨ | ì¼ë°˜ìƒì‹ 02_squad_ì§ˆë¬¸_ë‹µë³€_ì œì‹œë¬¸_ë§ë­‰ì¹˜ |
| í™˜ê²½/ê³µê³µ/ê³¼í•™ ë“± | í–‰ì •ë¬¸ì„œëŒ€ìƒ ê¸°ê³„ë…í•´ ë°ì´í„° |
| ì»´í“¨í„°ê³µí•™ | KorSciQA 1.0 |
| ê³¼í•™ê¸°ìˆ  | KorSciQA 2.0 |
| ì„¸ê³„ ë²•ë¥  | ì—‘ì†Œë¸Œë ˆì¸ ETRI ë²•ë ¹ QA |
| ë‹¤ì–‘í•¨ | ì—‘ì†Œë¸Œë ˆì¸ MRC í•œêµ­ì–´ QA |
| ë²•ë¥ /ê¸ˆìœµ | ê¸ˆìœµ ë²•ë¥  ë¬¸ì„œ ê¸°ê³„ë…í•´ ë°ì´í„° |
| ê¸°ìˆ ê³¼í•™ | ê¸°ìˆ ê³¼í•™ë¬¸ì„œ ê¸°ê³„ë…í•´ ë°ì´í„° |
| ë‰´ìŠ¤ | ë‰´ìŠ¤ê¸°ì‚¬ ê¸°ê³„ë…í•´ ë°ì´í„° |
| ë‹¤ì–‘í•¨ | ë…ì„œìë£Œ ê¸°ê³„ë…í•´ ë°ì´í„° |
| í•œêµ­ë¬¸í™” | í•œêµ­ë¬¸í™” ë°ì´í„° |
| ê³¼í•™ ê¸°ìˆ  ë…¼ë¬¸ | êµ­ë‚´ ë…¼ë¬¸ QA ë°ì´í„°ì…‹ 2.0 |
| ê²½ì œ/ìŠ¤í¬ì¸  | ê²½ì œÂ·ìŠ¤í¬ì¸  QA ë°ì´í„° |
| ë‹¤ì–‘í•¨ (ì˜ì–´) | SQuAD 2.0 |
| ì˜í•™/ìƒë¬¼í•™ | BioASQ |
| ë‹¤ì–‘í•¨ | MS-MARCO 2.1 |
| ë¬¸í•™/ê³¼í•™/ë‰´ìŠ¤ | COQA |

---

# ğŸ” ë°ì´í„° ì „ì²˜ë¦¬

## 1ï¸âƒ£ Deduplication
- TF-IDF ê¸°ë°˜ ì¤‘ìš”ë„ ê³„ì‚°  
- MinHash + LSH ê¸°ë°˜ ì¤‘ë³µ ì œê±°  
- Paraphrase Identification ëª¨ë¸ í™œìš©  

## 2ï¸âƒ£ Privacy Reduction
- NER ê¸°ë°˜ ê°œì¸ì •ë³´(P.I.I) ì œê±°  
- ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹  

## 3ï¸âƒ£ Data Cleaning
- HTML/CSS ì œê±°  
- ë…¸ì´ì¦ˆ ì œê±°  
- ì €í’ˆì§ˆ ë°ì´í„° í•„í„°ë§  
- ì •í˜•í™” ë° êµ¬ì¡°í™”  

---

# âš™ï¸ Fine-Tuning ì „ëµ

## ğŸ“Œ Base Model
```
vaiv/GeM2-Llamion-14B-Chat
```

## ğŸ“Œ QLoRA ì ìš©
- 4bit NF4 ì–‘ìí™”  
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ  
- ì¶”ë¡  íš¨ìœ¨ í–¥ìƒ  
- LoRA ê¸°ë°˜ ì €ì°¨ì› íŒŒë¼ë¯¸í„° í•™ìŠµ  

## ğŸ“Œ Human Feedback ê¸°ë°˜ ë¯¸ì„¸ì¡°ì •
- ë™ì¼ í”„ë¡¬í”„íŠ¸ ë‹¤ì¤‘ ì‘ë‹µ ìƒì„±  
- ì„ í˜¸ ì‘ë‹µ ì„ íƒ  
- ì¶”ê°€ í•™ìŠµ ì§„í–‰  

---

# ğŸ“‚ Repository êµ¬ì¡°

```
.
â”œâ”€â”€ adapter_model.safetensors
â”œâ”€â”€ adapter_config.json
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ special_tokens_map.json
â”œâ”€â”€ data_sample/
â”‚   â””â”€â”€ LongAnswer_100_public.csv
â””â”€â”€ README.md
```

> âš ï¸ ì „ì²´ 100K ë°ì´í„°ëŠ” í¬í•¨ë˜ì§€ ì•Šìœ¼ë©°, ê³µê°œ ê°€ëŠ¥í•œ 100ê°œ ìƒ˜í”Œë§Œ í¬í•¨ë©ë‹ˆë‹¤.

---

# ğŸš€ ëª¨ë¸ ì‚¬ìš© ë°©ë²•

```python
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer

base_model = "vaiv/GeM2-Llamion-14B-Chat"
adapter_path = "./"

tokenizer = AutoTokenizer.from_pretrained(adapter_path)

model = AutoModelForCausalLM.from_pretrained(
    base_model,
    load_in_4bit=True,
    device_map="auto"
)

model = PeftModel.from_pretrained(model, adapter_path)
```

---

# ğŸ“Š í•™ìŠµ ì„¤ì •

- **Learning Rate:** 4e-4  
- **Scheduler:** Cosine  
- **Warmup Ratio:** 0.06  
- **Epoch:** 1  
- **Gradient Accumulation:** 16  
- **Mixed Precision:** FP16  
- **Quantization:** 4bit NF4  

---

# ğŸ“ˆ ê¸°ëŒ€ íš¨ê³¼

- ë‹¨ìˆœ ìœ ì‚¬ë„ ê¸°ë°˜ RAG ëŒ€ë¹„ ì •í™•ë„ í–¥ìƒ  
- ë¬¸ì„œ ìœ ìš©ì„± í‰ê°€ ê¸°ë°˜ í™˜ê° ê°ì†Œ  
- ê·¼ê±° ê¸°ë°˜ Long Answer ìƒì„±  
- ë‹¤ë„ë©”ì¸ ì¼ë°˜í™” ê°€ëŠ¥ì„± í™•ë³´  

---

# âš ï¸ í•œê³„

- Retrieval í’ˆì§ˆ ì˜ì¡´ì„±  
- threshold ì„¤ì • ë¯¼ê°ë„ ì¡´ì¬  
- ìµœì‹  ì •ë³´ ë°˜ì˜ í•œê³„  
- ì™„ì „í•œ Fact-checking ëª¨ë¸ì€ ì•„ë‹˜  

---

# ğŸ‘¨â€ğŸ’» ê°œë°œ í™˜ê²½

- Python 3.10  
- Transformers 4.41+  
- PEFT 0.11+  
- BitsAndBytes  
- HuggingFace Datasets  

---

# ğŸ† ê²°ê³¼

- **ë¶„ë¥˜ ì§€í‘œ:** 1ìœ„  
- **ìƒì„± ì§€í‘œ:** 6ìœ„  
